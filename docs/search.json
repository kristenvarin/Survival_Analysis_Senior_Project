[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Survival Analysis Senior Project",
    "section": "",
    "text": "1 Survival Analysis"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "3  References",
    "section": "",
    "text": "test"
  },
  {
    "objectID": "Kaplan_Meier.html#kaplan-meier-curve",
    "href": "Kaplan_Meier.html#kaplan-meier-curve",
    "title": "2  Kaplan Meier",
    "section": "2.2 Kaplan Meier Curve",
    "text": "2.2 Kaplan Meier Curve\nThe Kaplan Meier curve is a graphical representation of survival analysis. Similar to the survival probabilities discussed previously, the Kaplan Meier curve shows the relationships between time, which is typically plotted on the x-axis, and probability of survival, which is typically on the y-axis. The curve always ranges from 0 to 1 and is right skewed."
  },
  {
    "objectID": "Kaplan_Meier.html#kaplan-meier-in-r",
    "href": "Kaplan_Meier.html#kaplan-meier-in-r",
    "title": "2  Kaplan Meier",
    "section": "2.3 Kaplan Meier in R",
    "text": "2.3 Kaplan Meier in R\nLuckily, modern software makes these calculations easy and fast, as well as plotting them with confidence intervals and risk tables. The survival package in R has a function called Surv() that takes input data and creates a response object recording survival time for each observation. The survfit() function can be used to calculate the Kaplan Meier survival estimate for each time that a new event occurs. This object can then be used for the response in the regression functionSurvfit2() in the ggsurvfit package, which plots the Kaplan Meier curve for the data. The function takes into account right censoring as well, marking censored times with a \\(+\\) symbol in the object created and then editing the regression accordingly (Zabor, E). A new data set with censored times will be created to demonstrate this process. To do this, a 0 will be recorded for some individuals at times before t = 10.\n\n# Load Packages\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(knitr)\nlibrary(survival)\nlibrary(ggplot2)\nlibrary(ggsurvfit)\nlibrary(gt)\n\n\n# Create data set\nid &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\ntime &lt;- c(1, 2, 10, 4, 5, 6, 10, 8, 9, 10)\nstatus &lt;- c(1, 1, 0, 0, 1, 0, 0, 1, 1, 0)\ncensor &lt;- data.frame(id, time, status)\n\n\n# View the Data Set with censored times\n#| label: tbl-censor\n#| tbl-cap: \"Example Data Set with Censored Times\"\n\ncensor %&gt;% gt(caption = \"Example Data Set with Censored Times\") %&gt;%\n  cols_label(id = \"ID\", time = \"Time\", status = \"Status\") %&gt;%\n  tab_source_note(source_note = \"Table 3\") \n\n\n\n\n\n  Example Data Set with Censored Times\n  \n    \n    \n      ID\n      Time\n      Status\n    \n  \n  \n    1\n1\n1\n    2\n2\n1\n    3\n10\n0\n    4\n4\n0\n    5\n5\n1\n    6\n6\n0\n    7\n10\n0\n    8\n8\n1\n    9\n9\n1\n    10\n10\n0\n  \n  \n    \n      Table 3\n    \n  \n  \n\n\n\n\nsee ?tbl-censor\n\n# Surv() Function shows the time of event or censored time for each observation\ntimes2 &lt;- Surv(censor$time, censor$status)\ntimes2\n\n [1]  1   2  10+  4+  5   6+ 10+  8   9  10+\n\n\n\n# Calculate survival object\ns2 &lt;- survfit(times2 ~ 1, data = censor)\n# See the structure of this object\nstr(s2)\n\nList of 16\n $ n        : int 10\n $ time     : num [1:8] 1 2 4 5 6 8 9 10\n $ n.risk   : num [1:8] 10 9 8 7 6 5 4 3\n $ n.event  : num [1:8] 1 1 0 1 0 1 1 0\n $ n.censor : num [1:8] 0 0 1 0 1 0 0 3\n $ surv     : num [1:8] 0.9 0.8 0.8 0.686 0.686 ...\n $ std.err  : num [1:8] 0.105 0.158 0.158 0.221 0.221 ...\n $ cumhaz   : num [1:8] 0.1 0.211 0.211 0.354 0.354 ...\n $ std.chaz : num [1:8] 0.1 0.149 0.149 0.207 0.207 ...\n $ type     : chr \"right\"\n $ logse    : logi TRUE\n $ conf.int : num 0.95\n $ conf.type: chr \"log\"\n $ lower    : num [1:8] 0.732 0.587 0.587 0.445 0.445 ...\n $ upper    : num [1:8] 1 1 1 1 1 ...\n $ call     : language survfit(formula = times2 ~ 1, data = censor)\n - attr(*, \"class\")= chr \"survfit\"\n\n\n\n# View the survival estimate for each time an event occurs\ns2$time\n\n[1]  1  2  4  5  6  8  9 10\n\nround(s2$surv, 2)\n\n[1] 0.90 0.80 0.80 0.69 0.69 0.55 0.41 0.41\n\n\n\n# Plot the survival curve\n#| label: fig-survcurv\n#| tbl-cap: \"Kaplan Meier Survival Curve\"\n\nsurvfit2(Surv(time, status) ~ 1, data = censor) %&gt;% \n  ggsurvfit() +\n  labs(\n    x = \"Time\",\n    y = \"Overall survival probability\",\n    title = \"Kaplan Meier Survival Curve\"\n  ) + \n  scale_x_continuous(breaks=seq(0,10,by=2)) + \n  scale_y_continuous(breaks=seq(0,1,by=.2)) +\n  add_risktable()\n\n\n\n\nsee ?fig-survcurv"
  },
  {
    "objectID": "index.html#survival-analysis-background",
    "href": "index.html#survival-analysis-background",
    "title": "Survival Analysis Senior Project",
    "section": "1.1 Survival Analysis Background",
    "text": "1.1 Survival Analysis Background\nSurvival analysis is a type of statistical analysis used for analyzing the relationship between time and an event of interest occurring for individuals. The name survival analysis implies that the most common outcome analyzed is death, but many other events can be analyzed including: time it takes to begin recovering from treatment or time until a disease is contracted. These analyses are specifically helpful when comparing groups of people such as treatment groups in a clinical trial. Survival analysis can reveal whether certain treatments are more effective than others in helping individuals to live longer or avoid certain outcomes of interest, such as heart attacks."
  },
  {
    "objectID": "index.html#example-dataset-in-r",
    "href": "index.html#example-dataset-in-r",
    "title": "Survival Analysis Senior Project",
    "section": "1.2 Example dataset in R",
    "text": "1.2 Example dataset in R\nTo demonstrate survival analysis, an example dataset was created including ten observations and a time variable ranging from one to ten. Each observation was either assigned a 1, which represented the event occurrence, or a 0, representing no event occurrence. For those assigned a 1, a survival time was assigned in the range of 1 to 9. For those assigned a 0, a time of 10 was assigned, representing the end of the hypothetical study. To create a survival curve, the following steps need to be taken: finding the probability of survival at each time from 0 to 10 and plotting each point must be plotted on a graph. For the first point, probability of survival is always a 1 because every participant begins the study alive. For the first point in the dataset, the observation was assigned a 1 at time 1. When an individual experiences the outcome of interest, the total probability of survival for the group decreases, which is why survival curves have a rightly skewed distribution. The probability of surviving to time 1 would be the number of participants that did not experience the outcome divided by the total number of participants in the study, which would be nine participants divided by 10 subjects, or 0.9. After calculating the probability for each point in a similar way, the survival curve can be graphed (Figure 1). Summary statistics can also be calculated for these values.\nTable walking through the example probabilities here"
  },
  {
    "objectID": "index.html#censoring-background",
    "href": "index.html#censoring-background",
    "title": "Survival Analysis Senior Project",
    "section": "1.3 Censoring Background",
    "text": "1.3 Censoring Background\nOne issue with survival analysis data is the problem of an individual being lost-to-follow-up, meaning data could not be collected for them at some point during the study. This causes the outcome of interest to not be recorded for that individual, so the survival time for that individual can not be analyzed as it would not be accurate. When this happens, the survival times for those individuals are recorded as censored, causing standard analysis techniques to be inappropriate for these data. There are three types of censoring that can occur. The first type of censoring is called right censoring, which happens if an individual begins the study but then is lost-to-follow-up at some point during the study before it ends. The censored survival time for these individuals is thus equal to the total time they were known to be alive in the study’s observation period before they were lost-to-follow-up. Some common examples of when right censoring is needed include: an individual moving away from the study and not being able to participate or when an individual dies due to a non-related event after the study begins. Another type of censoring is called left censoring. In this type, the individual experiences lost-to-follow-up before the observation period begins. This would happen, for example, in a study that tracks patient recovery from a surgery, but with an observation period beginning one a month after the surgery took place. If a patient died less than a month after surgery, their survival time would need to be left censored. The final type of censoring is called interval censoring, which happens when a patient comes in and out of the study, making it possible for them to experience the outcome of interest during a period of time when they aren’t being observed. This often happens when recurrence is being tracked in a study. One example could be if recurrence of cancer is being tracked and the study checks in with patients every month. If an individual does not have cancer after the first month but then does after the second month, the recurrence time is somewhere between one and two months, and it therefore needs to be interval censored (Collet (2003)). Out of the three types, right censoring is the most common and will be demonstrated in the example data-set."
  },
  {
    "objectID": "Kaplan_Meier.html#kaplan-meier-survival-estimate",
    "href": "Kaplan_Meier.html#kaplan-meier-survival-estimate",
    "title": "2  Kaplan Meier",
    "section": "2.1 Kaplan Meier Survival Estimate",
    "text": "2.1 Kaplan Meier Survival Estimate\nThe Kaplan Meier survival estimate is how survival probabilities can be calculated while factoring in censored times. The Kaplan Meier survival estimate is used to calculate probability of survival at a given time where \\(S(t_j)\\) is the probability of being alive at time \\(t_j\\), \\(S(t_{j-1})\\) is the probability of being alive at \\(t_{j-1}\\), \\(n_j\\) is the number of patients alive just before \\(t_j\\), \\(d_j\\) is the number of events at \\(t_j\\), and \\(j\\) is the time interval of interest. The equation is \\(S(t_j)=S(t\\_{j-1})(1-\\frac{d_j}{n_j})\\) (Clark et al.). The equation essentially divides the surviving individuals by the individuals at risk, similar to the previous calculations shown. However, Kaplan Meier curves adjust for right-censored times by dropping observations from the total number of individuals at risk, \\(n_j\\), after their censored time has been reached. This adjustment prevents overestimating the survival probability because it no longer assumes censored individuals are still alive or and at risk (Goel et al)."
  },
  {
    "objectID": "Kaplan_Meier.html#log-rank-test",
    "href": "Kaplan_Meier.html#log-rank-test",
    "title": "2  Kaplan Meier",
    "section": "2.4 Log-Rank Test",
    "text": "2.4 Log-Rank Test\nOne of the most common applications of survival analysis and Kaplan Meier curves is for comparing survival statistics between two groups. One example of this might be if a study is comparing survival after two different treatment plans. The Log-Rank Test is a statistical test that tests the null hypothesis that there is no difference between the survival estimates of two groups at any point in time (Rich et al.). The only adjustment needed in R to factor in groups is to use the grouping variable as a predictor in the model (Zabor, E).\n\n# Create a data set to compare to surv2\nid &lt;- c(1:20)\ntime &lt;- c(8, 7, 10, 8, 5, 10, 10, 8, 9, 10, 1, 2, 1, 4, 5, 3, 4, 10, 8, 1)\nstatus &lt;- c(0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1)\ngroup &lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2 ,2 ,2, 2, 2)\nsurv3 &lt;- data.frame(id, time, status)\n\nThe survdiff function works similarly to the survfit function, but compares groups. The two curves are statistically different at the five percent level.\n\nsurvdiff(Surv(time, status) ~ group, data = surv3)\n\nCall:\nsurvdiff(formula = Surv(time, status) ~ group, data = surv3)\n\n         N Observed Expected (O-E)^2/E (O-E)^2/V\ngroup=1 10        4     6.91      1.23      4.81\ngroup=2 10        6     3.09      2.75      4.81\n\n Chisq= 4.8  on 1 degrees of freedom, p= 0.03 \n\n\n\n# Plot the two curves\n\n#| label: fig-survcurv2\n#| tbl-cap: \"Kaplan Meier Survival Curve by Group\"\nsurvfit2(Surv(time, status) ~ group, data = surv3) %&gt;% \n  ggsurvfit() +\n  labs(\n    x = \"Days\",\n    y = \"Overall survival probability\",\n    title = \"Kaplan Meier Survival Curve by Group\"\n  ) + \n  scale_x_continuous(breaks=seq(0,10,by=2)) + \n  scale_y_continuous(breaks=seq(0,1,by=.2)) +\n  add_risktable()\n\n\n\n# find quarto caption option; references and titles\n\nsee ?fig-survcurv2"
  },
  {
    "objectID": "index.html#example-data-set-in-r",
    "href": "index.html#example-data-set-in-r",
    "title": "Survival Analysis Senior Project",
    "section": "1.2 Example data set in R",
    "text": "1.2 Example data set in R\nTo demonstrate survival analysis, an example data set was created including ten observations with the following columns: a. \\(id\\) variable for each observation, a \\(time\\) variable ranging from 1 to 10, and a \\(status\\) variable that was either a 1, which represented the event occurrence, or a 0, representing no event occurrence. For those assigned a 1, a survival time was assigned in the range of 1 to 9, representing the time that individual survived until the event occurred for them. For those assigned a 0, a time of t = 10 was assigned, suggesting that they lasted until the end of the hypothetical study without the event occurring. Table 1.1 shows these data.\n\n# Load Packages\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(knitr)\nlibrary(survival)\nlibrary(ggsurvfit)\nlibrary(gt)\n\n\n# Create a simple data set\nid &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\ntime &lt;- c(1, 2, 4, 5, 6, 8, 9, 10, 10, 10)\nstatus &lt;- c(1, 1, 1, 1, 1, 1, 1, 0, 0, 0)\nsurv &lt;- data.frame(id, time, status)\n\n\nsurv %&gt;% gt(caption = \"Example Data Set with ID, Status, and Time\") %&gt;%\n  cols_label(id = \"ID\", time = \"Time\", status = \"Status\") %&gt;%\n  tab_source_note(source_note = \"Table 1\") \n\n\n\n\n\n\n  Table 1.1:  surv table 1 \n  \n    \n    \n      ID\n      Time\n      Status\n    \n  \n  \n    1\n1\n1\n    2\n2\n1\n    3\n4\n1\n    4\n5\n1\n    5\n6\n1\n    6\n8\n1\n    7\n9\n1\n    8\n10\n0\n    9\n10\n0\n    10\n10\n0\n  \n  \n    \n      Table 1\n    \n  \n  \n\n\n\n\n\nTo perform survival analysis on these data, the probability of survival at each time from t = 0 to t = 10 can be calculated by dividing the amount of people surviving until that time by the total amount of people in the study. For the first observation in the example data, probability of survival is equal to 1, or 100%, because every participant would presumably begin the study alive. To calculate the probability of survival for time t = 1, the number of participants that did not experience the outcome of interest by t = 1 would be divided by 10, the total number of observations in the study. In this case, 9 participants survived until time t = 1, because only one observation was assigned a 1 between times t = 0 and t = 1. Dividing this total by the 10 total observations in the study shows that the probability of surviving to time 1 is 0.9, or 90%. As time increases, the total probability of survival for the group will decrease in the range of 1 to 0 because more people will be experiencing the outcome. This is why survival curves have a rightly skewed distribution. Table 1.2 shows the survival probabilities for each observation.\n\n# Calculate survival probabilities\nprobabilities &lt;- data.frame(\n  Number_alive = c(10, 9, 8, 8, 7, 6, 5, 4, 3, 3, 3),\n  Time = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10),\n  Probability = c(1, 0.9, 0.8, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.3, 0.3))\n\n\nprobabilities %&gt;% gt(caption = \"Probability of Survival Based on Time\") %&gt;%\n  cols_label(Number_alive = \"Number alive\", Time = \"Time\", Probability = \"Probability\") %&gt;%\n  tab_source_note(source_note = \"Table 2\") \n\n\n\n\n\n\n  Table 1.2:  probabilities \n  \n    \n    \n      Number alive\n      Time\n      Probability\n    \n  \n  \n    10\n0\n1.0\n    9\n1\n0.9\n    8\n2\n0.8\n    8\n3\n0.8\n    7\n4\n0.7\n    6\n5\n0.6\n    5\n6\n0.5\n    4\n7\n0.4\n    3\n8\n0.3\n    3\n9\n0.3\n    3\n10\n0.3\n  \n  \n    \n      Table 2"
  },
  {
    "objectID": "Kaplan_Meier.html#kaplan-meier-curve-and-descriptive-statistics",
    "href": "Kaplan_Meier.html#kaplan-meier-curve-and-descriptive-statistics",
    "title": "2  Kaplan Meier",
    "section": "2.2 Kaplan Meier Curve and Descriptive Statistics",
    "text": "2.2 Kaplan Meier Curve and Descriptive Statistics\nThe Kaplan Meier curve is a graphical representation of survival analysis. Similar to the survival probabilities discussed previously, the Kaplan Meier curve shows the relationships between time, which is typically plotted on the x-axis, and probability of survival, which is typically on the y-axis. The curve always ranges from 0 to 1 and is right skewed. Useful summary statistics for a Kaplan Meier Survival curve include confidence intervals and the median. A 95% confidence interval for each point can be found by using the formula \\(S_t ± 1.96 * SE(S_t)\\). The median value is typically reported rather than the mean because mean survival time cannot be reported reliably for those who have not experienced the outcome of interest yet. The median can be found by finding the time when probability of survival is equal to 0.5. Thus, the median can only be reported when at least half of the participants experienced the outcome of interest during the study (Sowmya R. Rao, PhD; David A. Schoenfeld, PhD)."
  },
  {
    "objectID": "KaplanMeier.html#kaplan-meier-survival-estimate",
    "href": "KaplanMeier.html#kaplan-meier-survival-estimate",
    "title": "2  Kaplan Meier",
    "section": "2.1 Kaplan Meier Survival Estimate",
    "text": "2.1 Kaplan Meier Survival Estimate\nThe Kaplan Meier survival estimate is how survival probabilities can be calculated while factoring in censored times. The Kaplan Meier survival estimate is used to calculate probability of survival at a given time where \\(S(t_j)\\) is the probability of being alive at time \\(t_j\\), \\(S(t_{j-1})\\) is the probability of being alive at \\(t_{j-1}\\), \\(n_j\\) is the number of patients alive just before \\(t_j\\), \\(d_j\\) is the number of events at \\(t_j\\), and \\(j\\) is the time interval of interest. The equation is \\(S(t_j)=S(t\\_{j-1})(1-\\frac{d_j}{n_j})\\) (Clark (2003)). The equation essentially divides the surviving individuals by the individuals at risk, similar to the previous calculations shown. However, Kaplan Meier curves adjust for right-censored times by dropping observations from the total number of individuals at risk, \\(n_j\\), after their censored time has been reached. This adjustment prevents overestimating the survival probability because it no longer assumes censored individuals are still alive or and at risk (Goel (2010))."
  },
  {
    "objectID": "KaplanMeier.html#kaplan-meier-curve-and-descriptive-statistics",
    "href": "KaplanMeier.html#kaplan-meier-curve-and-descriptive-statistics",
    "title": "2  Kaplan Meier",
    "section": "2.2 Kaplan Meier Curve and Descriptive Statistics",
    "text": "2.2 Kaplan Meier Curve and Descriptive Statistics\nThe Kaplan Meier curve is a graphical representation of survival analysis. Similar to the survival probabilities discussed previously, the Kaplan Meier curve shows the relationships between time, which is typically plotted on the x-axis, and probability of survival, which is typically on the y-axis. The curve always ranges from 0 to 1 and is right skewed. Useful summary statistics for a Kaplan Meier Survival curve include confidence intervals and the median. A 95% confidence interval for each point can be found by using the formula \\(S_t ± 1.96 * SE(S_t)\\). The median value is typically reported rather than the mean because mean survival time cannot be reported reliably for those who have not experienced the outcome of interest yet. The median can be found by finding the time when probability of survival is equal to 0.5. Thus, the median can only be reported when at least half of the participants experienced the outcome of interest during the study (Rao (2023))."
  },
  {
    "objectID": "KaplanMeier.html#kaplan-meier-in-r",
    "href": "KaplanMeier.html#kaplan-meier-in-r",
    "title": "2  Kaplan Meier",
    "section": "2.3 Kaplan Meier in R",
    "text": "2.3 Kaplan Meier in R\nLuckily, modern software makes these calculations easy and fast, as well as plotting them with confidence intervals and risk tables. A new data set with censored times will be created to demonstrate this process. To do this, a 0 will be recorded for some individuals at times before t = 10. Table 2.1 shows this data set’s structure.\n\n# Load Packages\nlibrary(tidyverse) \n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(knitr)\nlibrary(survival)\nlibrary(ggsurvfit)\nlibrary(gt)\n\n\n# Create data set\nid &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n#id &lt;- c(5, 5, 7, 7, 8, 8, 9, 9, 1, 1)\ntime &lt;- c(1, 2, 10, 4, 5, 6, 10, 8, 9, 10)\nstatus &lt;- c(1, 1, 0, 0, 1, 0, 0, 1, 1, 0)\ncensor &lt;- data.frame(id, time, status)\n\n\ncensor %&gt;% gt(caption = \"Example Data Set with Censored Times\") %&gt;%\n  cols_label(id = \"ID\", time = \"Time\", status = \"Status\") %&gt;%\n  tab_source_note(source_note = \"Table 3\") \n\n\n\n\n\n\n  Table 2.1:  Example Data Set with Censored Times \n  \n    \n    \n      ID\n      Time\n      Status\n    \n  \n  \n    1\n1\n1\n    2\n2\n1\n    3\n10\n0\n    4\n4\n0\n    5\n5\n1\n    6\n6\n0\n    7\n10\n0\n    8\n8\n1\n    9\n9\n1\n    10\n10\n0\n  \n  \n    \n      Table 3\n    \n  \n  \n\n\n\n\n\nThe survival package in R has a function called Surv() that takes input data and creates a response object recording survival time for each observation. The function takes in the time variable and the status variable. The function takes into account right censoring as well, marking censored times with a \\(+\\) symbol in the object created (Zabor (2023)).\n\n# Show the time of event or censored time for each observation\ntimes &lt;- Surv(censor$time, censor$status)\ntimes\n\n [1]  1   2  10+  4+  5   6+ 10+  8   9  10+\n\n\nThe survfit() function can be used to calculate the Kaplan Meier survival estimate for each time that a new event occurs. The function takes in the response object created by the Surv() function in order to drop censored observations from the regression. We use ~ 1 because we are not including predictor variables in the model. The function returns a survival object that can be used to plot the Kaplan Meier curve and calculate summary statistics. The time variable in the object created by the survfit() function shows the time of each event, and the surv variable shows the survival probability for the remaining individuals after each event occurs.\n\n# Calculate survival object\ns1 &lt;- survfit(times ~ 1, data = censor)\n# View the survival time for each time an event occurs\ns1$time\n\n[1]  1  2  4  5  6  8  9 10\n\n# View survival probability for remaining individuals after each event occurs \nround(s1$surv, 2)\n\n[1] 0.90 0.80 0.80 0.69 0.69 0.55 0.41 0.41\n\n\nThe ggsurvfit package can be used to plot the Kaplan Meier curve for this data using the previously created s1 object. Figure 2.1 shows the Kaplan Meier curve for predicting the event. The risk table shows the number of individuals at risk at each time point and the number of events that occurred at each time point.\n\ns1 %&gt;% \n  ggsurvfit() +\n  labs(\n    x = \"Time\",\n    y = \"Overall survival probability\",\n    title = \"Kaplan Meier Survival Curve\"\n  ) + \n  scale_x_continuous(breaks=seq(0,10,by=2)) + \n  scale_y_continuous(breaks=seq(0,1,by=.2)) +\n  add_risktable()\n\n\n\n\nFigure 2.1: Kaplan Meier Survival Curve"
  },
  {
    "objectID": "KaplanMeier.html#log-rank-test",
    "href": "KaplanMeier.html#log-rank-test",
    "title": "2  Kaplan Meier",
    "section": "2.4 Log-Rank Test",
    "text": "2.4 Log-Rank Test\nOne of the most common applications of survival analysis and Kaplan Meier curves is for comparing survival times between two groups. One example of when this might be useful is if a study is comparing survival after two different treatment plans. A data set with two groups will be created to demonstrate this process.\n\n# Create new data set\ntime &lt;- c(8, 7, 10, 8, 5, 3, 4, 10, 6, 1)\nstatus &lt;- c(0, 1, 0, 1, 0, 1, 0, 0, 1, 1)\ngroup &lt;- c(1, 1, 1, 1, 1, 2, 2 ,2, 2, 2)\nsurv2 &lt;- data.frame(time, status, group)\n\nTo run analysis, the statistical test called the Log-Rank Test can be used to test the null hypothesis that there is no difference between the survival estimates of two groups at any point in time (Rich (2010)). The test is conducted by comparing the observed number of event with an estimated number of events for each group at each time. To model this, we need to record some values of interest from our existing data. The first, \\(n1t\\), represents the number of people alive and still in the study, or at risk, at time t in group 1. Similarly, \\(n2t\\) is the number at risk in group 2 at time t. \\(nt\\) is the sum of these two values at time t, representing the total number of people at risk in the study at time t. \\(o1t\\) is the number of observed events occurring at time t in group 1, \\(o2t\\) is observed events occurring at time t in group 2, and \\(ot\\) is the total observed events across both groups at time t. To calculate expected number of events, the assumption that the two curves are identical is used. The expected number of events at a time t is for group i calculated by the formula \\(E_{it} = \\frac{N_{it} \\times O_{t}}{N_{t}}\\), where \\(N_{it}\\) is the observed number of events in group i at time t, \\(O_{t}\\) is the total number of events in all groups at time t, and \\(N_{t}\\) is the total number observations at risk in all groups at time t (Sullivan (2016)). Table 2.2 shows the creation of all of these values, where \\(e1t\\) is the expected number of events at time t in group 1, \\(e2t\\) is the expected number of events at time t in group 2, and \\(et\\) is the total expected number of events across both groups at time t. Cumulative sums are also calculated for each of these values.\n\nTime &lt;- c(1, 3, 4, 5, 6, 7, 8, 10)\nN1t &lt;- c(5, 5, 5, 5, 4, 4, 3, 1)\nN2t &lt;- c(5, 4, 3, 2, 2, 1, 1, 1)\nO1t &lt;- c(0, 0, 0, 0, 0, 1, 1, 0)\nO2t &lt;- c(1, 1, 0, 0, 1, 0, 0, 0)\n\nlog_rank &lt;- data.frame(Time, N1t, N2t, O1t, O2t)\n\n# Calculate Totals\nlog_rank$Nt &lt;- log_rank$N1t + log_rank$N2t\nlog_rank$Ot &lt;- log_rank$O1t + log_rank$O2t\nlog_rank$E1t &lt;- (log_rank$N1t * log_rank$Ot) / log_rank$Nt\nlog_rank$E2t &lt;- (log_rank$N2t * log_rank$Ot) / log_rank$Nt\n\nround(log_rank, 2) %&gt;% \n  gt() %&gt;% \n  tab_header(\"Values Needed to Calculate Chi-Square Statistic\") %&gt;% \n  cols_label(Time = \"Time\", N1t = \"Number at Risk in Group 1\", N2t = \"Number at Risk in Group 2\", Nt = \"Total Number at Risk\", O1t = \"Observed Events in Group 1\", O2t = \"Observed Events in Group 2\", Ot = \"Total Observed Events\", E1t = \"Expected Events in Group 1\", E2t = \"Expected Events in Group 2\")\n\n\n\n\n\nTable 2.2:  Calculation of Log-Rank Test Statistic \n  \n    \n      Values Needed to Calculate Chi-Square Statistic\n    \n    \n    \n      Time\n      Number at Risk in Group 1\n      Number at Risk in Group 2\n      Observed Events in Group 1\n      Observed Events in Group 2\n      Total Number at Risk\n      Total Observed Events\n      Expected Events in Group 1\n      Expected Events in Group 2\n    \n  \n  \n    1\n5\n5\n0\n1\n10\n1\n0.50\n0.50\n    3\n5\n4\n0\n1\n9\n1\n0.56\n0.44\n    4\n5\n3\n0\n0\n8\n0\n0.00\n0.00\n    5\n5\n2\n0\n0\n7\n0\n0.00\n0.00\n    6\n4\n2\n0\n1\n6\n1\n0.67\n0.33\n    7\n4\n1\n1\n0\n5\n1\n0.80\n0.20\n    8\n3\n1\n1\n0\n4\n1\n0.75\n0.25\n    10\n1\n1\n0\n0\n2\n0\n0.00\n0.00\n  \n  \n  \n\n\n\n\n\nTo test the null hypothesis that there is no difference between the survival estimates of two groups at any point in time, a test statistics is needed. For the Log-Rank test, a Chi-Square test statistic is used because the data follows a Chi-Square curve rather than a normal distribution. The Chi-Square test statistic is calculated by the formula \\(X^2 = \\sum_{i=1}^k \\frac{(\\sum{O_{it}} - \\sum{E_{it}})^2}{\\sum{Vi}}\\), where \\(\\sum_{0}^T{O_{it}}\\) is the sum of the observed number of events in group i over the entire time interval and \\(\\sum_{0}^T{E_{it}}\\) is the sum of the expected number of events in group i over the entire time interval. The difference of the sums of these two values are divided by the sum of the variance. The variance for group 1 at time t is calculated by the formula \\(V_{1t} = \\frac{N_{1t} \\times N_{2t} \\times O_{t} \\times (N_{t} - O_{t})}{N_{t}^2 \\times (N_{t} - 1)}\\) (Collet (2003)). The variance for group 2 is calculated similarly, and the total variance is calculated by the formula \\(V_{t} = V_{1t} + V_{2t}\\). Table 2.3 shows the calculation of the Chi-Square test statistic for the data set. In the table, \\(V1t\\) is the variance of the number of events at time t in group 1, \\(V2t\\) is the variance of the number of events at time t in group 2, \\(Vt\\) is the total variance of the number of events across both groups at time t, \\(sum_{Vt}\\) is the cumulative sum of the total variance across all times, and \\(X2\\) is the Chi-Square test statistic.\n\nlog_rank$V1t &lt;- (log_rank$N1t * log_rank$N2t * log_rank$Ot * (log_rank$Nt - log_rank$Ot)) / (log_rank$Nt^2 * (log_rank$Nt - 1))\n\nlog_rank$V2t &lt;- (log_rank$N1t * log_rank$N2t * log_rank$Ot * (log_rank$Nt - log_rank$Ot)) / (log_rank$Nt^2 * (log_rank$Nt - 1))\n\nround(log_rank, 2) %&gt;% \n  gt() %&gt;% \n  tab_header(\"Calculation of Variance\") %&gt;% \n  cols_label(Time = \"Time\", N1t = \"Number at Risk in Group 1\", N2t = \"Number at Risk in Group 2\", Nt = \"Total Number at Risk\", O1t = \"Observed Events in Group 1\", O2t = \"Observed Events in Group 2\", Ot = \"Total Observed Events\", E1t = \"Expected Events in Group 1\", E2t = \"Expected Events in Group 2\", V1t = \"Variance of Number of Events in Group 1\", V2t = \"Variance of Number of Events in Group 2\")\n\n\n\n\n\nTable 2.3:  Calculation of Variance \n  \n    \n      Calculation of Variance\n    \n    \n    \n      Time\n      Number at Risk in Group 1\n      Number at Risk in Group 2\n      Observed Events in Group 1\n      Observed Events in Group 2\n      Total Number at Risk\n      Total Observed Events\n      Expected Events in Group 1\n      Expected Events in Group 2\n      Variance of Number of Events in Group 1\n      Variance of Number of Events in Group 2\n    \n  \n  \n    1\n5\n5\n0\n1\n10\n1\n0.50\n0.50\n0.25\n0.25\n    3\n5\n4\n0\n1\n9\n1\n0.56\n0.44\n0.25\n0.25\n    4\n5\n3\n0\n0\n8\n0\n0.00\n0.00\n0.00\n0.00\n    5\n5\n2\n0\n0\n7\n0\n0.00\n0.00\n0.00\n0.00\n    6\n4\n2\n0\n1\n6\n1\n0.67\n0.33\n0.22\n0.22\n    7\n4\n1\n1\n0\n5\n1\n0.80\n0.20\n0.16\n0.16\n    8\n3\n1\n1\n0\n4\n1\n0.75\n0.25\n0.19\n0.19\n    10\n1\n1\n0\n0\n2\n0\n0.00\n0.00\n0.00\n0.00\n  \n  \n  \n\n\n\n\n\nFor group 1 at time 1, we would calculate \\(E_{1t} = \\frac{5 \\times 1}{10} = 0.50\\) and for group 2 at time 1, \\(E_{2t} = \\frac{5 \\times 1}{10} = 0.50\\). We would repeat for each group at each time and then sum the values to get \\(\\sum_{t=1}^t{E_{i}}\\) for each group. For group 1, \\(\\sum_{t=1}^t{E_{1}} = 0.50 + 0.56 + 0 + 0 + 0.67 + 0.80 + 0.75 + 0 = 3.27\\) and for group 2, \\(\\sum_{t=0}^t{E_{2}} = 0.50 + 0.44 + 0 + 0 + 0.33 + 0.20 + 0.25 + 0 = 1.73\\). The sum of the observed events for group 1 is 2 and for group 2 is 3. For group 1 at time 1, we would calculate \\(V_1t = \\frac{5 \\times 5 \\times 1 \\times (10-1)}{10^2 \\times (10-1)} = 0.25\\) Table 2.4 shows the rest of the variances calculated for both groups for the surv2 data set.\n\nsum_O1t &lt;- cumsum(log_rank$O1t)\nsum_O2t &lt;- cumsum(log_rank$O2t)\nsum_E1t &lt;- cumsum(log_rank$E1t)\nsum_E2t &lt;- cumsum(log_rank$E2t)\nsum_V1t &lt;- cumsum(log_rank$V1t)\nsum_V2t &lt;- cumsum(log_rank$V2t)\n\n# Create table with each of the last values \nsum_stats &lt;- data.frame(sum_O1t, sum_O2t, sum_E1t, sum_E2t, sum_V1t, sum_V2t)\n# Get the last row of summary statistics\nsum_stats &lt;- sum_stats[nrow(sum_stats), ]\nsum_stats$X2_group1 &lt;- ((sum_stats$sum_O1t - sum_stats$sum_E1t)^2 / sum_stats$sum_V1t)\nsum_stats$X2_group2 &lt;- ((sum_stats$sum_O2t - sum_stats$sum_E2t)^2 / sum_stats$sum_V2t)\n\nround(sum_stats, 2) %&gt;% \n  gt() %&gt;% \n  tab_header(\"Calculation of Chi Square Statistic\") %&gt;% \n  cols_label(sum_O1t = \"Sum of Observed Events in Group 1\", sum_O2t = \"Sum of Observed Events in Group 2\", sum_E1t = \"Sum of Expected Events in Group 1\", sum_E2t = \"Sum of Expected Events in Group 2\", sum_V1t = \"Sum of Variance of Number of Events in Group 1\", sum_V2t = \"Sum of Variance of Number of Events in Group 2\", X2_group1 = \"Chi Square Statistic for Group 1\", X2_group2 = \"Chi Square Statistic for Group 2\")\n\n\n\n\n\nTable 2.4:  Calculation of Chi Square Statistic \n  \n    \n      Calculation of Chi Square Statistic\n    \n    \n    \n      Sum of Observed Events in Group 1\n      Sum of Observed Events in Group 2\n      Sum of Expected Events in Group 1\n      Sum of Expected Events in Group 2\n      Sum of Variance of Number of Events in Group 1\n      Sum of Variance of Number of Events in Group 2\n      Chi Square Statistic for Group 1\n      Chi Square Statistic for Group 2\n    \n  \n  \n    2\n3\n3.27\n1.73\n1.07\n1.07\n1.52\n1.52\n  \n  \n  \n\n\n\n\n\nWith all of these values, we can calculate the Chi Square test statistic, \\(X^2i = \\frac{(\\sum{O_{it}} - \\sum{E_{it}})^2}{V_{it}}\\). We get \\(X^2group1 = \\frac{(2 - 3.27)^2}{1.07} = 1.51\\) and \\(X^2group1 = \\frac{(3 - 1.73)^2}{1.07} = 1.51\\). The test statistic can then be compared to a Chi-Square distribution with one k-1 degrees of freedom, with k being the number of groups. So, for this example, there is one degree of freedom. If the p-value is less than 0.05, then we can reject the null hypothesis that there is no difference between the survival estimates of the two groups (Sullivan (2016)).\nClearly, calculating the test statistic is very tedious, even for a data set with 10 observations. The survdiff function can be used to run a Log-Rank test in R, making it much easier to run the test. The function takes in the response object created by the Surv() function and the grouping variable (Zabor (2023)). It returns a Chi-Square statistic and a p-value. We can see that the p-value is much higher than 0.05, indicating that we do not have evidence to reject the null hypothesis, and thus that there is no difference between the survival estimates of the two groups.\n\n# Calculate times for events in this data set\ntimes2 &lt;- Surv(surv2$time, surv2$status)\n# Run a log rank test based on group variable\ntest_stat &lt;- survdiff(times2 ~ group, data = surv2)\ntest_stat\n\nCall:\nsurvdiff(formula = times2 ~ group, data = surv2)\n\n        N Observed Expected (O-E)^2/E (O-E)^2/V\ngroup=1 5        2     3.27     0.495      1.52\ngroup=2 5        3     1.73     0.937      1.52\n\n Chisq= 1.5  on 1 degrees of freedom, p= 0.2 \n\n\nThe only adjustment needed for plotting the Kaplan Meier curves for two groups is to include the grouping variable while making the survival object using the survfit function (Zabor (2023)). The two survival curves are depicted in Figure 2.2.\n\n# Create survival object using group as a predictor\ns2 &lt;- survfit(Surv(time, status) ~ group, data = surv2)\n\n# Plot the two curves\ns2 %&gt;% \n  ggsurvfit() +\n  labs(\n    x = \"Days\",\n    y = \"Overall survival probability\",\n    title = \"Kaplan Meier Survival Curve by Group\"\n  ) + \n  scale_x_continuous(breaks=seq(0,10,by=2)) + \n  scale_y_continuous(breaks=seq(0,1,by=.2)) +\n  add_risktable()\n\n\n\n\nFigure 2.2: Kaplan Meier Survival Curve by Group"
  },
  {
    "objectID": "KaplanMeier.html#case-study",
    "href": "KaplanMeier.html#case-study",
    "title": "2  Kaplan Meier",
    "section": "2.5 Case Study",
    "text": "2.5 Case Study\nThe next example uses a data set with variables for predicting death in patients with cirrhosis, which is permanent scarring of the liver. The data set is from a clinical trial conducted by the Mayo Clinic from 1974 to 1984. The data set contains 424 primary biliary cirrhosis patients with 20 variables (Fedesoriano (2021)). To conduct survival analysis, the Status variable needs to be transformed into an indicator variable, labelled event, coded as a 1 representing death and 0 representing censored. The N_Days variable will be used for the time variable, indicating number of days since the beginning of the trial.\n\ncirrhosis &lt;- read_csv(\"data/cirrhosis.csv\", show_col_types = FALSE)\ncirrhosis &lt;- cirrhosis %&gt;% mutate(event = if_else(Status == 'D', 1, 0)) \n\nThe main interest of this data is to explore the difference in survival time between patients taking the drug of interest, D-penicillamine, and those given a placebo. The variable Drug indicates which group the patient was in and will be used as the grouping variable for a Log-Rank Test. Below, we calculate a survival object for this data and then use the survdiff function to run a Log-Rank Test.\n\n# Calculate times and survival object\ntimes3 &lt;- Surv(cirrhosis$N_Days, cirrhosis$event)\ns3 &lt;- survfit(times3 ~ Drug, data = cirrhosis)\n# Run a log rank test based on drug group\nsurvdiff(times3 ~ Drug, data = cirrhosis)\n\nCall:\nsurvdiff(formula = times3 ~ Drug, data = cirrhosis)\n\nn=312, 106 observations deleted due to missingness.\n\n                       N Observed Expected (O-E)^2/E (O-E)^2/V\nDrug=D-penicillamine 158       65     63.2    0.0502     0.102\nDrug=Placebo         154       60     61.8    0.0513     0.102\n\n Chisq= 0.1  on 1 degrees of freedom, p= 0.7 \n\n\nFrom the Log-Rank test, we see that the p-value is 0.7, which is mush larger than 0.05. This indicates that the test was not statistically significant at the five percent level. Thus, there was no significant difference between patient outcome between the two treatment groups. For patients with biliary cirrhosis, D-penicillamine is not an effective drug for preventing death.\nWe can again visualize the difference in survival curves in Figure 2.3.\n\ns3 %&gt;% \n  ggsurvfit() +\n  labs(\n    x = \"Time\",\n    y = \"Overall survival probability\",\n    title = \"Kaplan Meier Survival Curve\"\n  ) + \n  add_risktable()\n\n\n\n\nFigure 2.3: Kaplan Meier Survival Curve Predicting Death from Cirrhosis\n\n\n\n\nIt is important to note the limitations of this analysis. The Kaplan Meier Curve is not a suitable fit for a complex, real-world data set such as the cirrhosis data. It is a nonparametric method of analysis, which means that it assumes no form of distribution and no additional factors influencing the outcome of interest. To create a Kaplan Meier curve and run the Log-Rank test, we ignored all other factors included int the data. In the next section, we will discuss other methods that can be used for survival analysis that can account for other factors."
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Survival Analysis Senior Project",
    "section": "1.4 References",
    "text": "1.4 References\n\n\n\n\nCollet, David. 2003. Modelling Survival Data in Medical Research. Chapman & Hall/CRC."
  },
  {
    "objectID": "KaplanMeier.html#references",
    "href": "KaplanMeier.html#references",
    "title": "2  Kaplan Meier",
    "section": "2.6 References",
    "text": "2.6 References\n\n\n\n\nClark, Bradburn, T. G. 2003. “Survival Analysis Part i: Basic Concepts and First Analyses.” British Journal of Cancer, May. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2394262/.\n\n\nCollet, David. 2003. Modelling Survival Data in Medical Research. Chapman & Hall/CRC.\n\n\nFedesoriano. 2021. “Cirrhosis Prediction Dataset.” www.kaggle.com/datasets/fedesoriano/cirrhosis-prediction-dataset/data.\n\n\nGoel, Khanna, M. K. 2010. “Understanding Survival Analysis: Kaplan-Meier Estimate.” International Journal of Ayurveda Research. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3059453.\n\n\nRao, & Schoenfeld, S. R. 2023. “Statistical Primer for Cardiovascular Research.” AHA Journals. https://www.ahajournals.org/doi/pdf/10.1161/circulationaha.106.614859.\n\n\nRich, Neely, J. T. 2010. “A Practical Guide to Understanding Kaplan-Meier Curves.” Otolaryngology–Head and Neck Surgery: Official Journal of American Academy of Otolaryngology-Head and Neck Surgery. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3932959/.\n\n\nSullivan, LaMorte, L. 2016. “Comparing Survival Curves.” sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_survival/BS704_Survival5.html.\n\n\nZabor, E. C. 2023. “Survival Analysis in r.” https://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html."
  },
  {
    "objectID": "KaplanMeier.html",
    "href": "KaplanMeier.html",
    "title": "2  Kaplan Meier",
    "section": "",
    "text": "3 break into chunks of code and write up\nsurvfit2(Surv(N_Days, event) ~ 1, data = cirrhosis) %&gt;% \n  ggsurvfit() +\n  labs(\n    x = \"Time\",\n    y = \"Overall survival probability\",\n    title = \"Kaplan Meier Survival Curve\"\n  ) + \n  add_risktable()\n\n\n\n\nFigure 3.1: Kaplan Meier Survival Curve Predicting Death from Cirrhosis"
  },
  {
    "objectID": "HazardAnalysis.html",
    "href": "HazardAnalysis.html",
    "title": "3  HazardAnalysis",
    "section": "",
    "text": "4 Kaplan Meier"
  },
  {
    "objectID": "HazardAnalysis.html#references",
    "href": "HazardAnalysis.html#references",
    "title": "3  Cox Proportional Hazards Regression",
    "section": "3.9 References",
    "text": "3.9 References\n\n\n\n\nClark, Bradburn, T. G. 2003. “Survival Analysis Part i: Basic Concepts and First Analyses.” British Journal of Cancer, May. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2394262/.\n\n\nCollet, David. 2003. Modelling Survival Data in Medical Research. Chapman & Hall/CRC.\n\n\n“Cox Proportional-Hazards Model.” n.d. www.sthda.com/english/wiki/cox-proportional-hazards-model.\n\n\nWaagepetersen, Rasmus. 2022. “Cox’s Proportional Hazards Model and Cox’s Partial Likelihood.” https://people.math.aau.dk/~rw/Undervisning/DurationAnalysis/Slides/lektion3.pdf."
  },
  {
    "objectID": "HazardAnalysis.html#introduction",
    "href": "HazardAnalysis.html#introduction",
    "title": "3  Cox Proportional Hazards Regression",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\nSo far, we have dealt with calculating survival probability using a Kaplan Meier curve. While a Kaplan Meier curve is useful for predicting survival probability for simple data, it can not always be used since its a nonparametric method, meaning it follows no prior assumptions about the data. When data becomes more complex and variables about individuals need to be considered, other methods need to be used. One of these methods, proportional hazard analysis, similarly focuses on time-to-event data, but can be used for more realistic scenarios that deal with additional explanatory variables for the event of interest (Clark (2003)). For example, we can use hazard analysis to calculate the probability of a person recovering from a disease based on type of treatment, while also including variables that could affect the outcome such as age, sex or history of drugs. A hazard function can be more useful during real-world analysis than the Kaplan Meier curve previously discussed."
  },
  {
    "objectID": "HazardAnalysis.html#hazard-ratios",
    "href": "HazardAnalysis.html#hazard-ratios",
    "title": "3  Cox Proportional Hazards Regression",
    "section": "3.3 Hazard Ratios",
    "text": "3.3 Hazard Ratios\nThe goal of hazard analysis is to create a hazard function for modelling time to event data, where the outcome \\(h(t)\\) or \\(λ(t)\\) is the probability of the event occurring for a subject who has lasted until time \\(t\\) (Clark (2003)). The hazard function is modeled using hazard ratios, which express the ratio between the hazard of an event between two groups at a time. The hazard ratio between two groups can be expressed as \\(v = \\frac{h_1(t)}{h_2(t)}\\) (Collet (2003))."
  },
  {
    "objectID": "HazardAnalysis.html#cox-proportional-hazards-model",
    "href": "HazardAnalysis.html#cox-proportional-hazards-model",
    "title": "3  Cox Proportional Hazards Regression",
    "section": "3.4 Cox Proportional Hazards Model",
    "text": "3.4 Cox Proportional Hazards Model\nThe Cox proportional hazards model is expressed in terms of the hazard function on an individual \\(i\\) at time \\(t\\). This function is expressed as \\(h_i(t) = vh_0(t)\\), where \\(h_0(t)\\) is the baseline hazard function and \\(v\\) is the hazard ratio (Collet (2003)). The baseline hazard function is the hazard function for a subject with all explanatory variables equal to zero. For the models we will discuss, the hazard ratio \\(v\\) is set to equal \\(exp(\\beta)\\) since the hazard ratio cannot be a negative value. The parameter \\(beta\\) is thus the log of the hazard ratio, expressed \\(\\beta = log(v)\\). Any value of \\(\\beta\\) will output a positive value \\(v\\). We can include many explanatory variables in the hazard function such as factors, which can take on different levels, or variates, which can be any value on a continuous scale. With many predictors, the Cox proportional hazards model can be expressed as \\(h_i(t) = h_0(t)exp(\\beta_1x_{1i} + \\beta_2x_{2i} + ... + \\beta_px_{pi})\\), where \\(h_0(t)\\) is the baseline hazard function, \\(x_1\\) to \\(x_p\\) are the values of the explanatory variables for individual \\(i\\), and \\(\\beta_1\\) to \\(\\beta_p\\) are the regression coefficients. The model can also be expressed as a linear model in terms of the log of the ratios between the two hazard functions, looking like \\(log(\\frac{h_i(t)}{h_0(t)}) = \\beta_1x_{1i} + \\beta_2x_{2i} + ... + \\beta_px_{pi}\\) (Collet (2003))."
  },
  {
    "objectID": "HazardAnalysis.html#example-data-set",
    "href": "HazardAnalysis.html#example-data-set",
    "title": "3  Cox Proportional Hazards Regression",
    "section": "3.6 Example Data Set",
    "text": "3.6 Example Data Set\n\n# Load Packages\nlibrary(tidyverse) \n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(knitr)\nlibrary(survival)\nlibrary(ggsurvfit)\nlibrary(gt)\n\nWe will again create a simple data set to demonstrate the process. Let’s recall the surv2 data set we created earlier, now with an additional variable, age Table 3.1.\n\ntime &lt;- c(8, 7, 10, 8, 5, 3, 4, 10, 6, 1)\nstatus &lt;- c(0, 1, 0, 1, 0, 1, 0, 0, 1, 1)\ngroup &lt;- c(1, 1, 1, 1, 1, 2, 2 ,2, 2, 2)\nage &lt;- c(40, 62, 37, 67, 44, 70, 50, 45, 61, 62)\nsurv3 &lt;- data.frame(time, status, group, age)\n\n\nsurv3 %&gt;% gt(caption = \"Example Data Set with Status, Time, Group, and Age\") %&gt;%\n  cols_label(time = \"Time\", status = \"Status\", group = \"Group\", age = \"Age\") \n\n\n\n\n\n\n  Table 3.1:  surv table 3 \n  \n    \n    \n      Time\n      Status\n      Group\n      Age\n    \n  \n  \n    8\n0\n1\n40\n    7\n1\n1\n62\n    10\n0\n1\n37\n    8\n1\n1\n67\n    5\n0\n1\n44\n    3\n1\n2\n70\n    4\n0\n2\n50\n    10\n0\n2\n45\n    6\n1\n2\n61\n    1\n1\n2\n62\n  \n  \n  \n\n\n\n\n\nLet’s start by calculating a hazard function between groups 1 and 2 and ignoring age. Recall that \\(h_i(t) = h_0(t)exp(\\beta_1x_{1i} + \\beta_2x_{2i} + ... + \\beta_px_{pi})\\). So for group 1, \\(h_1(t) = h_0(t)exp(\\beta_1x_{1})\\), with \\(x_{1}\\) being 1 since the individual is in group 1. For group 2, \\(h_2(t) = h_0(t)exp(\\beta_1x_{2})\\), with \\(x_{2}\\) being 2 since the individual is in group 2. We can then calculate the hazard ratio between the two groups as \\(v = \\frac{h_1(t)}{h_2(t)} = \\frac{h_0(t)exp(\\beta_1x_{1})}{h_0(t)exp(\\beta_1x_{2})} = exp(\\beta_1x_{1} - \\beta_1x_{2}) = exp(\\beta_1(x_{1} - x_{2}))\\). Note that the baseline hazard function, \\(h_0(t)\\), cancels out, which makes sense since this model does not assume a specific shape.\nTo find the value for \\(\\beta_1\\), we need to use something called the maximum likelihood test.\nWhen looking at multiple predictors, such as and and group, the parameter estimates are found by the equation:\nTo determine the values for the predictors, we must use the partial likelihood test.\nWe can calculate the cumulative hazard ratio, \\(v\\) of the event occurring in the group of individuals with a status of 1 compared to the group of individuals with a status of 0. We can calculate the hazard of the event occurring for an individual in group 1 at time t, \\(h_1(t)\\), by dividing the number of individuals who died in the group of individuals with a status of 1 by the total number of individuals in the group of individuals with a status of 1.\n\ncumulative? This can be expressed as \\(v = \\frac{\\frac{d_1}{n_1}}{\\frac{d_0}{n_0}}\\)."
  },
  {
    "objectID": "HazardAnalysis.html#hazard-analysis-in-r",
    "href": "HazardAnalysis.html#hazard-analysis-in-r",
    "title": "3  Cox Proportional Hazards Regression",
    "section": "3.7 Hazard Analysis in R",
    "text": "3.7 Hazard Analysis in R\nSimilarly to before with the Kaplan Meier curve, we can use R to model the hazard function. The coxph() function in the survival package returns the coefficients of the cox proportional hazards model as well as the p value for the coefficients, allowing us to determine whether each coefficient is significant (“Cox Proportional-Hazards Model” (n.d.)). Below, we see that the coefficient on the age predictor is significant, but the coefficient for group is not. This means that, when controlling for the other variables, the hazard of the event occurring is not significantly different between the two groups, but the hazard of the event occurring is significantly different for individuals of different ages.\n\ncoxph(Surv(time, status) ~ group + age, data = surv3)\n\nCall:\ncoxph(formula = Surv(time, status) ~ group + age, data = surv3)\n\n          coef exp(coef) se(coef)     z      p\ngroup  2.63387  13.92750  1.78647 1.474 0.1404\nage    0.18887   1.20789  0.09323 2.026 0.0428\n\nLikelihood ratio test=10.39  on 2 df, p=0.005533\nn= 10, number of events= 5"
  },
  {
    "objectID": "HazardAnalysis.html#proportional-hazards",
    "href": "HazardAnalysis.html#proportional-hazards",
    "title": "3  Cox Proportional Hazards Regression",
    "section": "3.2 Proportional Hazards",
    "text": "3.2 Proportional Hazards\nThe proportional hazards model, also known as the Cox regression model, is a semi-parametric model. This is because it assumes proportional hazards, or that the hazard of an event occurring is the same for all individuals, yet does not assume a specific distribution (Collet (2003)). The proportional hazard model also assumes that the hazard ratio between two groups is constant over time. This means that the hazard ratio between two groups is the same at any time \\(t\\), thus making the model proportional. In other words, the instantaneous hazard of an event occurring between two individuals of different groups will remain constant at all times, or the effect of the predictors is the same at all times (“Cox Proportional-Hazards Model” (n.d.))."
  },
  {
    "objectID": "HazardAnalysis.html#method-of-partial-likelihood",
    "href": "HazardAnalysis.html#method-of-partial-likelihood",
    "title": "3  Cox Proportional Hazards Regression",
    "section": "3.5 Method of Partial Likelihood",
    "text": "3.5 Method of Partial Likelihood\nIn the Cox proportional hazards model, there are two unknowns: the baseline hazard function, \\(h_0(t)\\), and the regression coefficients, \\(\\beta_1\\) to \\(\\beta_p\\). The method of partial likelihood, first discovered by Cox himself, allows us to estimate the regression coefficients without knowing the baseline hazard function (Collet (2003)). We do this by maximizing the likelihood of the observed data (Collet (2003)). Basically, it is a way of choosing coefficient estimates that will be most likely to output the exact same data points we have. One key assumption of this method is that there are no ties, or deaths at the same time, in the data (Waagepetersen (2022)). We must make this assumption because the way this method works is by ranking the times of death in each group."
  },
  {
    "objectID": "HazardAnalysis.html#case-study",
    "href": "HazardAnalysis.html#case-study",
    "title": "3  Cox Proportional Hazards Regression",
    "section": "3.8 Case Study",
    "text": "3.8 Case Study\nLet’s look back at the Cirrhosis data set."
  }
]